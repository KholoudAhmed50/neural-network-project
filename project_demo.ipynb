{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPpo9fFCgttoU0uodM/5e3X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import mnist\n","\n","# Import your custom neural-network library\n","from lib.layers import Dense\n","from lib.activations import ReLU, Sigmoid, Tanh\n","from lib.losses import MSELoss\n","from lib.optimizer import SGD\n","from lib.network import Sequential\n","\n","np.random.seed(0)\n","\n"],"metadata":{"id":"zgbAQYFTpQjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_loss(losses, title=\"Loss Curve\"):\n","    plt.figure(figsize=(6,4))\n","    plt.plot(losses)\n","    plt.title(title)\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.grid()\n","    plt.show()\n"],"metadata":{"id":"FWxkBUQzprVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def numerical_gradient(model, X, Y, loss_fn, epsilon=1e-5):\n","    \"\"\"\n","    Performs gradient check on first Dense layer only.\n","    \"\"\"\n","    # Forward + backward to get analytical gradients\n","    y_pred = model.forward(X)\n","    _ = loss_fn.forward(Y, y_pred)\n","    grad = loss_fn.backward(Y, y_pred)\n","    model.backward(grad)\n","\n","    dense = None\n","    for layer in model.layers:\n","        if isinstance(layer, Dense):\n","            dense = layer\n","            break\n","\n","    errors = []\n","\n","    for W in [dense.W, dense.b]:\n","        it = np.nditer(W, flags=['multi_index'], op_flags=['readwrite'])\n","        while not it.finished:\n","            idx = it.multi_index\n","            old_val = W[idx]\n","\n","            # +epsilon\n","            W[idx] = old_val + epsilon\n","            y_pos = model.forward(X)\n","            loss_pos = loss_fn.forward(Y, y_pos)\n","\n","            # -epsilon\n","            W[idx] = old_val - epsilon\n","            y_neg = model.forward(X)\n","            loss_neg = loss_fn.forward(Y, y_neg)\n","\n","            # reset\n","            W[idx] = old_val\n","\n","            numerical = (loss_pos - loss_neg) / (2 * epsilon)\n","            analytical = dense.grad_W[idx] if W is dense.W else dense.grad_b[idx]\n","\n","            rel_error = abs(numerical - analytical) / (abs(numerical) + abs(analytical) + 1e-12)\n","            errors.append(rel_error)\n","\n","            it.iternext()\n","\n","    return np.max(errors)\n"],"metadata":{"id":"aj1pev5rpu7I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tiny test network\n","model = Sequential([\n","    Dense(2, 3),\n","    Tanh(),\n","    Dense(3, 1),\n","    Sigmoid(),\n","])\n","\n","loss_fn = MSELoss()\n","\n","# Small input\n","X = np.array([[0.1, -0.2]])\n","Y = np.array([[1]])\n","\n","max_error = numerical_gradient(model, X, Y, loss_fn)\n","max_error\n"],"metadata":{"id":"oCjeQMPmp0oK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_xor = np.array([[0,0],[0,1],[1,0],[1,1]])\n","Y_xor = np.array([[0],[1],[1],[0]])\n"],"metadata":{"id":"q1HIvLXzpTXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xor_model = Sequential([\n","    Dense(2, 4),\n","    Tanh(),\n","    Dense(4, 1),\n","    Sigmoid(),\n","])\n","\n","loss_fn = MSELoss()\n","optimizer = SGD(lr=0.1)\n"],"metadata":{"id":"KL7yvTfUpJ_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 5000\n","losses = []\n","\n","for epoch in range(epochs):\n","    y_pred = xor_model.forward(X_xor)\n","    loss = loss_fn.forward(Y_xor, y_pred)\n","    grad = loss_fn.backward(Y_xor, y_pred)\n","    xor_model.backward(grad, lr=0.1)\n","    losses.append(loss)\n","\n","plot_loss(losses, \"XOR Training Loss\")\n","print(\"Predictions:\")\n","print(xor_model.forward(X_xor))\n"],"metadata":{"id":"ZlacmNg6qHvi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(x_train, _), (x_test, y_test_labels) = mnist.load_data()\n","\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test  = x_test.astype(\"float32\") / 255.0\n","\n","# Flatten to vectors: 28×28 → 784\n","x_train = x_train.reshape(-1, 784)\n","x_test  = x_test.reshape(-1, 784)\n"],"metadata":{"id":"xOqXa8dFqSbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_dim = 32\n","\n","autoencoder = Sequential([\n","    Dense(784, 256),\n","    ReLU(),\n","    Dense(256, encoder_dim),   # Latent\n","    ReLU(),\n","    Dense(encoder_dim, 256),\n","    ReLU(),\n","    Dense(256, 784),\n","    Sigmoid(),\n","])\n","\n","loss_fn = MSELoss()\n"],"metadata":{"id":"uDsEEq7KqUeO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","batch_size = 256\n","losses = []\n","\n","for epoch in range(epochs):\n","    perm = np.random.permutation(len(x_train))\n","    x_train_shuffled = x_train[perm]\n","\n","    epoch_loss = 0\n","    for i in range(0, len(x_train), batch_size):\n","        Xb = x_train_shuffled[i:i+batch_size]\n","\n","        y_pred = autoencoder.forward(Xb)\n","        loss = loss_fn.forward(Xb, y_pred)\n","        grad = loss_fn.backward(Xb, y_pred)\n","        autoencoder.backward(grad, lr=0.01)\n","\n","        epoch_loss += loss\n","\n","    losses.append(epoch_loss / (len(x_train)//batch_size))\n","    print(f\"Epoch {epoch+1}/{epochs} — Loss: {losses[-1]}\")\n","\n","plot_loss(losses, \"Autoencoder Training Loss\")\n"],"metadata":{"id":"8R_3oBtiqX4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n = 10\n","samples = x_test[:n]\n","recons = autoencoder.forward(samples)\n","\n","plt.figure(figsize=(12,4))\n","for i in range(n):\n","    # original\n","    plt.subplot(2,n,i+1)\n","    plt.imshow(samples[i].reshape(28,28), cmap='gray')\n","    plt.axis(\"off\")\n","    # reconstructed\n","    plt.subplot(2,n,i+1+n)\n","    plt.imshow(recons[i].reshape(28,28), cmap='gray')\n","    plt.axis(\"off\")\n","plt.show()\n"],"metadata":{"id":"UC3OfblXqb1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode(model, X):\n","    \"\"\"\n","    Runs only encoder part:\n","    Dense(784→256) → ReLU → Dense(256→32) → ReLU\n","    \"\"\"\n","    out = model.layers[0].forward(X)\n","    out = model.layers[1].forward(out)\n","    out = model.layers[2].forward(out)\n","    out = model.layers[3].forward(out)\n","    return out\n","\n","X_train_latent = encode(autoencoder, x_train)\n","X_test_latent  = encode(autoencoder, x_test)\n","\n","print(\"Latent shape:\", X_train_latent.shape)\n"],"metadata":{"id":"6A1SJ0nnqkiz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf = svm.SVC(kernel=\"rbf\")\n","clf.fit(X_train_latent[:20000], y_test_labels[:20000])   # train on subset for speed\n","\n","y_pred = clf.predict(X_test_latent)\n","acc = accuracy_score(y_test_labels, y_pred)\n","acc\n"],"metadata":{"id":"1tXG6sLcqnfa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(y_test_labels, y_pred)\n","plt.figure(figsize=(6,6))\n","plt.imshow(cm)\n","plt.title(\"Confusion Matrix\")\n","plt.colorbar()\n","plt.show()\n"],"metadata":{"id":"HTZx5EJOqsWP"},"execution_count":null,"outputs":[]}]}